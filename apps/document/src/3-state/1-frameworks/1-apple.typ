In der Entwicklung von Augmented Reality Anwendungen bieten ARKit und RealityKit von Apple zwei wesentliche Frameworks, die Entwicklern erweiterte Werkzeuge zur Verfügung stellen, um AR-Anwendungen zu erstellen.

Eingeführt im Juni 2017, ermöglicht ARKit die Erstellung von Augmented Reality Anwendungen für iOS, indem es die Kamera, Prozessoren und Bewegungssensoren der Geräte nutzt, um die reale Umgebung des Benutzers zu analysieren. Eine der Schlüsselfunktionen ist die Ebenenerkennung, die es der Software erlaubt, horizontale Flächen wie Tische und Böden zu erkennen, auf denen dann digitale Objekte platziert werden können.

Zusätzlich zu dieser grundlegenden Funktionalität verfügt ARKit über eine Vielzahl fortschrittlicher Features. Hierzu zählt die Lichtschätzung, welche die Umgebungslichtverhältnisse analysiert und die Beleuchtung der digitalen Objekte entsprechend anpasst, um sie nahtlos in ihre Umgebung einzufügen.

Des Weiteren unterstützt ARKit das 3D-Objekterkennungs- und -tracking-Verfahren, das die Erkennung und Verfolgung realer 3D-Objekte ermöglicht und somit die Interaktionsmöglichkeiten innerhalb der Anwendung erweitert.

RealityKit, welches im Jahr 2019 vorgestellt wurde, ist speziell für die Erstellung realistischer und interaktiver AR-Erlebnisse konzipiert und bietet eine Reihe von Funktionen, die diese Ziele unterstützen. Es baut hierbei auf ARKit auf, bietet jedoch zusätzliche und verbesserte Werkzeuge und Technologien für eine verbesserte Darstellung und Interaktion.

Eine Hauptfunktion ist das fotorealistisches Rendering. Dies ermöglicht die Erzeugung von AR-Szenen mit hoher visueller Qualität, die nahtlos mit der realen Umgebung interagieren.

Ein weiteres wichtiges Merkmal ist die integrierte Physik-Engine, die es virtuellen Objekten ermöglicht, sich in der realen Welt auf natürliche Weise zu verhalten. Diese Engine berücksichtigt Faktoren wie Schwerkraft, Kollisionen und Interaktionen, um eine realistische Darstellung der AR-Erfahrung zu gewährleisten.